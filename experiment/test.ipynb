{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tuannm/sonhoang/Vietnamese-OCR-from-scratch-pytorch\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import math\n",
    "import numpy as np\n",
    "from typing import OrderedDict\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import transforms\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.nn.utils.clip_grad import clip_grad_norm_\n",
    "\n",
    "from utils.utils import AverageMeter, Eval, OCRLabelConverter\n",
    "from utils.utils import EarlyStopping, gmkdir\n",
    "from optim.optimizer import STLR\n",
    "from utils.utils import gaussian\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthDataset(Dataset):\n",
    "    def __init__(self, opt):\n",
    "        super(SynthDataset, self).__init__()\n",
    "        self.path = os.path.join(opt['path'], opt['imgdir'])\n",
    "        self.images = os.listdir(self.path)\n",
    "        self.nSamples = len(self.images)\n",
    "        f = lambda x: os.path.join(self.path, x)\n",
    "        self.imagepaths = list(map(f, self.images))\n",
    "        transform_list = [\n",
    "            transforms.Grayscale(1),\n",
    "            transforms.toTensor(),\n",
    "            transforms.Normalize((0.5, ), (0.5, ))\n",
    "        ]\n",
    "        self.transform = transforms.Compose(transform_list)\n",
    "        self.collate_fn = SynthCollator()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.nSamples\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        assert index <= len(self), 'index range error'\n",
    "        imagepath = self.imagepaths[index]\n",
    "        imagefile = os.path.basename(imagepath)\n",
    "        img = Image.open(imagepath)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        item = {'img': img, 'idx': index}\n",
    "        item['label'] = imagefile.split('_')[0]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthCollator(object):\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        width = [item['img'].shape[2] for item in batch]\n",
    "        indexes = [item['idx'] for item in batch]\n",
    "        imgs = torch.ones([len(batch), batch[0]['img'].shape[0], batch[0]['img'].shape[1],\n",
    "                           max(width)], dtype=torch.float32)\n",
    "        \n",
    "        for idx, item in enumerate(batch):\n",
    "            try:\n",
    "                imgs[idx, :, :, 0:item['img'].shape[2]] = item['img']\n",
    "            except:\n",
    "                print(imgs.shape)\n",
    "                \n",
    "        item = {'img': imgs, 'idx': indexes}\n",
    "        if 'label' in batch[0].keys():\n",
    "            labels = [item['label'] for item in batch]\n",
    "            item['label']  = labels\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, nIn, nHidden, nOut):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\n",
    "        self.embedding = nn.Linear(nHIdden * 2, nOut)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        self.rnn.flatten_parameters()\n",
    "        recurrent, _ = self.rnn(input)\n",
    "        T, b, h = recurrent.size()\n",
    "        t_rec = recurrent.view(T * b, h)\n",
    "        output = self.embedding(t_rec)\n",
    "        output = output.view(T, b, -1)\n",
    "        return output\n",
    "    \n",
    "class CRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, opt, leakyRelu=False):\n",
    "        super(CRNN, self).__init__()\n",
    "        \n",
    "        assert opt['imgH'] % 16 == 0, 'imgH has to be a multiple of 16'\n",
    "        \n",
    "        ks = [3, 3, 3, 3, 3, 3, 2] # kernel size\n",
    "        ps = [1, 1, 1, 1, 1, 1, 0] # padding size\n",
    "        ss = [1, 1, 1, 1, 1, 1, 1] # stride size\n",
    "        nm = [64, 128, 256, 256, 512, 512, 512] #\n",
    "        \n",
    "        cnn = nn.Sequential()\n",
    "\n",
    "        def convRelu(i, batchNormalization=False):\n",
    "            nIn = opt['nChannels'] if i == 0 else nm[i -1]\n",
    "            nOut = nm[i]\n",
    "            cnn.add_module(f'conv{i}',\n",
    "                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n",
    "        \n",
    "            if batchNormalization:\n",
    "                cnn.add_module(f'batchnorm{i}', nn.BatchNorm2d(nOut))\n",
    "            \n",
    "            if leakyRelu:\n",
    "                cnn.add_module(f'relu{i}', nn.LeakyReLU(0.2, inplace=True))\n",
    "            else:\n",
    "                cnn.add_module(f'relu{i}', nn.ReLU(True))\n",
    "                \n",
    "        convRelu(0)\n",
    "        cnn.add_module(f'pooling0', nn.MaxPool2d(2, 2)) # 64x16x64\n",
    "        convRelu(1)\n",
    "        cnn.add_module(f'pooling1', nn.MaxPool2d(2, 2)) # 128x8x32\n",
    "        convRelu(2, True)\n",
    "        convRelu(3)\n",
    "        cnn.add_module('pooling2',\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1))) # 256x4x16\n",
    "        convRelu(6, True) # 512x1x16\n",
    "        self.cnn = cnn\n",
    "        self.rnn = nn.Sequential()\n",
    "        self.rnn = nn.Sequential(\n",
    "            BidirectionalLSTM(opt['nHidden'] * 2, opt['nHidden'], opt['nHidden']),\n",
    "            BidirectionalLSTM(opt['nHidden'] * 2, opt['nHidden'], opt['nClasses'])\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # conv features\n",
    "        conv = self.cnn(input)\n",
    "        b, c, h, w = conv.size()\n",
    "        assert h == 1, \"the height of conv must be 1\"\n",
    "        conv = conv.squeeze(2)\n",
    "        conv = conv.permute(2, 0, 1) # [w, b, c]\n",
    "        # rnn features\n",
    "        output = self.rnn(conv)\n",
    "        output = output.transpose(1, 0) # Tbh to bth\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCTCLoss(nn.Module):\n",
    "    # T x B x H => Softmax on dimension 2\n",
    "    def __init__(self, dim = 2):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.ctc_loss = nn.CTCLoss(reduction='mean', zero_infinity=True)\n",
    "        \n",
    "    def forward(self, logits, labels, prediction_sizes, target_sizes):\n",
    "        EPS = 1e-7\n",
    "        loss = self.ctc_loss(logits, labels, prediction_sizes, target_sizes)\n",
    "        loss = self.sanitize(loss)\n",
    "        return self.debug(loss, logits, labels, prediction_sizes, target_sizes)\n",
    "    \n",
    "    def sanitize(self, loss):\n",
    "        EPS = 1e-7\n",
    "        if abs(loss.item() - float('inf')) < EPS:\n",
    "            return torch.zeros_like(loss)\n",
    "        \n",
    "        if math.isnan(loss.item()):\n",
    "            return torch.zeros_like(loss)\n",
    "        return loss\n",
    "    \n",
    "    def debug(self, loss, logits, labels, prediction_sizes, target_sizes):\n",
    "        if math.isnan(loss.item()):\n",
    "            print(\"Loss:\", loss)\n",
    "            print(\"logits:\", logits)\n",
    "            print(\"labels:\", labels)\n",
    "            print(\"prediction_sizes:\", prediction_sizes)\n",
    "            print(\"target_sizes:\", target_sizes)\n",
    "            raise Exception(\"NaN loss obtained. But why?\")\n",
    "        return loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCRTrainer(object):\n",
    "    def __init__(self, opt):\n",
    "        super(OCRTrainer, self).__init__()\n",
    "        self.data_train = opt['data_train']\n",
    "        self.data_val = opt['data_val']\n",
    "        self.model = opt['model']\n",
    "        self.criterion = opt['criterion']\n",
    "        self.optimizer = opt['optimizer']\n",
    "        self.schedule = opt['schedule']\n",
    "        self.converter = OCRLabelConverter(opt['alphabet'])\n",
    "        self.evaluator = Eval()\n",
    "        print(f'Scheduling is {self.schedue}')\n",
    "        self.scheduler = CosineAnnealingLR(self.optimizer, T_max=opt['epochs'])\n",
    "        self.batch_size = opt['batch_size']\n",
    "        self.count = opt['epoch']\n",
    "        self.epochs = opt['epochs']\n",
    "        self.cuda = opt['cuda']\n",
    "        self.collate_fn = opt['collate_fn']\n",
    "        self.init_meters()\n",
    "        \n",
    "    def init_meters(self):\n",
    "        self.avgTrainLoss = AverageMeter(\"Train loss\")\n",
    "        self.avgTrainCharAccuracy = AverageMeter(\"Train Character Accuracy\")\n",
    "        self.avgTrainWordAccuracy = AverageMeter(\"Train Word Accuracy\")\n",
    "        self.avgValLoss = AverageMeter(\"Validation loss\")\n",
    "        self.avgValCharAccuracy = AverageMeter(\"Validation Character Accuracy\")\n",
    "        self.avgValWordAccuracy = AverageMeter(\"Validation Word Accuracy\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.model(x)\n",
    "        return logits.transpose(1, 0)\n",
    "\n",
    "    def loss_fn(self, logits, targets, pred_sizes, target_sizes):\n",
    "        loss = self.criterion(logits, targets, pred_sizes, target_sizes)\n",
    "        return loss\n",
    "\n",
    "    def step(self):\n",
    "        self.max_grad_norm = 0.05\n",
    "        clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
    "        self.optimizer.step()\n",
    "    \n",
    "    def schedule_lr(self):\n",
    "        if self.schedule:\n",
    "            self.scheduler.step()\n",
    "            \n",
    "    def _run_batch(self, batch, report_accuracy=False, validation=False):\n",
    "        input_, targets = batch['img'], batch['label']\n",
    "        targets, lengths = self.converter.encode(targets)\n",
    "        logits = self.forward(input_)\n",
    "        logits = logits.contiguous().cpu()\n",
    "        logits = torch.nn.functional.log_softmax(logits, 2)\n",
    "        T, B, H = logits.size()\n",
    "        pred_sizes = torch.LongTensor([T for i in range(B)])\n",
    "        targets= targets.view(-1).contiguous()\n",
    "        loss = self.loss_fn(logits, targets, pred_sizes, lengths)\n",
    "        if report_accuracy:\n",
    "            probs, preds = logits.max(2)\n",
    "            preds = preds.transpose(1, 0).contiguous().view(-1)\n",
    "            sim_preds = self.converter.decode(preds.data, pred_sizes.data, raw=False)\n",
    "            ca = np.mean((list(map(self.evaluator.char_accuracy, list(zip(sim_preds, batch['label']))))))\n",
    "            wa = np.mean((list(map(self.evaluator.word_accuracy, list(zip(sim_preds, batch['label']))))))\n",
    "        return loss, ca, wa\n",
    "    \n",
    "    def run_epoch(self, validation=False):\n",
    "        if not validation:\n",
    "            loader = self.train_dataloader()\n",
    "            pbar = tqdm(loader, desc='Epoch: [%d]/[%d] Training'%(self.count, \n",
    "                self.epochs), leave=True)\n",
    "            self.model.train()\n",
    "        else:\n",
    "            loader = self.val_dataloader()\n",
    "            pbar = tqdm(loader, desc='Validating', leave=True)\n",
    "            self.model.eval()\n",
    "        outputs = []\n",
    "        for batch_nb, batch in enumerate(pbar):\n",
    "            if not validation:\n",
    "                output = self.training_step(batch)\n",
    "            else:\n",
    "                output = self.validation_step(batch)\n",
    "            pbar.set_postfix(output)\n",
    "            outputs.append(output)\n",
    "        self.schedule_lr()\n",
    "        if not validation:\n",
    "            result = self.train_end(outputs)\n",
    "        else:\n",
    "            result = self.validation_end(outputs)\n",
    "        return result\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        loss, ca, wa = self._run_batch(batch, report_accuracy=True)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.step()\n",
    "        output = OrderedDict({\n",
    "            'loss': abs(loss.item()),\n",
    "            'train_ca': ca.item(),\n",
    "            'train_wa': wa.item()\n",
    "            })\n",
    "        return output\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        loss, ca, wa = self._run_batch(batch, report_accuracy=True, validation=True)\n",
    "        output = OrderedDict({\n",
    "            'val_loss': abs(loss.item()),\n",
    "            'val_ca': ca.item(),\n",
    "            'val_wa': wa.item()\n",
    "            })\n",
    "        return output\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        # logging.info('training data loader called')\n",
    "        loader = torch.utils.data.DataLoader(self.data_train,\n",
    "                batch_size=self.batch_size,\n",
    "                collate_fn=self.collate_fn,\n",
    "                shuffle=True)\n",
    "        return loader\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        # logging.info('val data loader called')\n",
    "        loader = torch.utils.data.DataLoader(self.data_val,\n",
    "                batch_size=self.batch_size,\n",
    "                collate_fn=self.collate_fn)\n",
    "        return loader\n",
    "    \n",
    "    \n",
    "    def train_end(self, outputs):\n",
    "        for output in outputs:\n",
    "            self.avgTrainLoss.add(output['loss'])\n",
    "            self.avgTrainCharAccuracy.add(output['train_ca'])\n",
    "            self.avgTrainWordAccuracy.add(output['train_wa'])\n",
    "\n",
    "        train_loss_mean = abs(self.avgTrainLoss.compute())\n",
    "        train_ca_mean = self.avgTrainCharAccuracy.compute()\n",
    "        train_wa_mean = self.avgTrainWordAccuracy.compute()\n",
    "\n",
    "        result = {'train_loss': train_loss_mean, 'train_ca': train_ca_mean,\n",
    "        'train_wa': train_wa_mean}\n",
    "        # result = {'progress_bar': tqdm_dict, 'log': tqdm_dict, 'val_loss': train_loss_mean}\n",
    "        return result\n",
    "\n",
    "    def validation_end(self, outputs):\n",
    "        for output in outputs:\n",
    "            self.avgValLoss.add(output['val_loss'])\n",
    "            self.avgValCharAccuracy.add(output['val_ca'])\n",
    "            self.avgValWordAccuracy.add(output['val_wa'])\n",
    "\n",
    "        val_loss_mean = abs(self.avgValLoss.compute())\n",
    "        val_ca_mean = self.avgValCharAccuracy.compute()\n",
    "        val_wa_mean = self.avgValWordAccuracy.compute()\n",
    "\n",
    "        result = {'val_loss': val_loss_mean, 'val_ca': val_ca_mean,\n",
    "        'val_wa': val_wa_mean}\n",
    "        return result\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner(object):\n",
    "    def __init__(self, model, optimizer, savepath=None, resume=False):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.savepath = os.path.join(savepath, 'best.ckpt')\n",
    "        self.cuda = torch.cuda.is_available() \n",
    "        self.cuda_count = torch.cuda.device_count()\n",
    "        if self.cuda:\n",
    "            self.model = self.model.cuda()\n",
    "        self.epoch = 0\n",
    "        if self.cuda_count > 1:\n",
    "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "        self.best_score = None\n",
    "        if resume and os.path.exists(self.savepath):\n",
    "            self.checkpoint = torch.load(self.savepath)\n",
    "            self.epoch = self.checkpoint['epoch']\n",
    "            self.best_score=self.checkpoint['best']\n",
    "            self.load()\n",
    "        else:\n",
    "            print('checkpoint does not exist')\n",
    "\n",
    "    def fit(self, opt):\n",
    "        opt['cuda'] = self.cuda\n",
    "        opt['model'] = self.model\n",
    "        opt['optimizer'] = self.optimizer\n",
    "        logging.basicConfig(filename=\"%s/%s.csv\" %(opt['log_dir'], opt['name']), level=logging.INFO)\n",
    "        self.saver = EarlyStopping(self.savepath, patience=15, verbose=True, best_score=self.best_score)\n",
    "        opt['epoch'] = self.epoch\n",
    "        trainer = OCRTrainer(opt)\n",
    "        \n",
    "        for epoch in range(opt['epoch'], opt['epochs']):\n",
    "            train_result = trainer.run_epoch()\n",
    "            val_result = trainer.run_epoch(validation=True)\n",
    "            trainer.count = epoch\n",
    "            info = '%d, %.6f, %.6f, %.6f, %.6f, %.6f, %.6f'%(epoch, train_result['train_loss'], \n",
    "                val_result['val_loss'], train_result['train_ca'],  val_result['val_ca'],\n",
    "                train_result['train_wa'], val_result['val_wa'])\n",
    "            logging.info(info)\n",
    "            self.val_loss = val_result['val_loss']\n",
    "            print(self.val_loss)\n",
    "            if self.savepath:\n",
    "                self.save(epoch)\n",
    "            if self.saver.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    def load(self):\n",
    "        print('Loading checkpoint at {} trained for {} epochs'.format(self.savepath, self.checkpoint['epoch']))\n",
    "        self.model.load_state_dict(self.checkpoint['state_dict'])\n",
    "        if 'opt_state_dict' in self.checkpoint.keys():\n",
    "            print('Loading optimizer')\n",
    "            self.optimizer.load_state_dict(self.checkpoint['opt_state_dict'])\n",
    "\n",
    "    def save(self, epoch):\n",
    "        self.saver(self.val_loss, epoch, self.model, self.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
